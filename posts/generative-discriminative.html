<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>生成式和判别式模型 | 慢变量</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="icon" href="../icons/deceleration.png" type="image/png">

    <script type="application/json" id="post-metadata">
        {
            "id": "11404",
            "slug": "generative-discriminative",
            "title": "生成式和判别式模型",
            "createdAt": "2025-12-06",
            "day": "6",
            "month": "Dec",
            "categories": [
                "人工智能"
            ],
            "tags": [
                "有监督学习",
                "无监督学习",
                "生成模型",
                "判别模型"
            ],
            "summary": [],
            "link": "posts/generative-discriminative.html"
        }
    </script>

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>

<body>
    <div class="page-container">
        <div data-include="../partials/navbar.html"></div>

    <main class="main-content">
        <div class="wrapper">
            <article class="post">
                <div data-component="post-header"
                     data-day="6"
                     data-month="Dec"
                     data-title="生成式和判别式模型"
                     data-link=""
                     data-meta="&lt;span class=&quot;meta-item meta-categories&quot;&gt;分类：&lt;a href=&quot;#&quot;&gt;人工智能&lt;/a&gt;&lt;/span&gt;&lt;span class=&quot;meta-divider&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;meta-item meta-tags&quot;&gt;标签：&lt;a href=&quot;#&quot;&gt;有监督学习&lt;/a&gt;,&lt;a href=&quot;#&quot;&gt;无监督学习&lt;/a&gt;,&lt;a href=&quot;#&quot;&gt;生成模型&lt;/a&gt;,&lt;a href=&quot;#&quot;&gt;判别模型&lt;/a&gt;&lt;/span&gt;"
                     data-heading="h1"
                     data-meta-class="post-meta"
                     data-title-class="post-title"></div>

                <div class="post-content single-post-content">
                <p>在AI中，「学习」总是离不开数据，一个朴素但是真实的假设是：<strong>存在一个真实但未知的分布$p$</strong>，我们所能接触到的数据，都是从这个分布中采样得到的。针对采集到的数据的情况不同（有没有标签），我们一般有两种不同的学习方式：</p>
                <section class="post-section" id="有监督学习"><h2 data-heading-id="有监督学习">有监督学习</h2>
                <p>对于有监督学习，数据通常是以「输入-标签」对$(x,y)$的形式存在：
                $$
                (x, y) \sim p(x, y) \tag{1}
                $$
                有监督学习中最常见的任务是：<strong>给定输入$x$，预测标签$y$</strong>，也就是学习一个条件分布$p(y|x)$。这里的$x$可以是图像、文本、音频等各种形式的数据，$y$可以是类别标签、连续值、序列等各种形式的输出。如果站在概率论的角度，最自然的预测的规则就是<strong>最大后验概率（MAP）</strong>：
                $$
                \hat{y}(x) = \arg\max_y p(y|x) \tag{2}
                $$</p>
                <p>这个规则的直观意义是：</p>
                <blockquote class="cite">
                <p>看到输入$x$后，我们选择最有可能的输出$y$作为预测结果。</p>
                </blockquote>
                <p>但是现在的问题是：<strong>我们并不知道$p(y|x)$是什么</strong>，只能通过有限的训练数据去估计它：</p>
                <p>(1) 如果我们直接选择直接去建模$p(y|x)$：
                $$
                p(y|x) \approx p_\theta(y|x) \tag{3}
                $$
                这就是<strong>判别式模型（discriminative model）</strong>，它直接关注于输入和输出之间的关系。常见的判别式模型包括逻辑回归、支持向量机（SVM）、条件随机场（CRF）以及大多数深度学习模型（如分类神经网络）。</p>
                <p>假设我们有一个训练集$\{(x_i, y_i)\}_{i=1}^N$，其中$x_i$是输入，$y_i$是对应的标签。假设数据是独立同分布的，对于整个数据集中的数据，预测时有：
                $$
                \arg\max_y p(y|x) \approx \arg\max_\theta \prod_{i=1}^N p_{\theta}(y_i|x_i) \tag{4}
                $$
                这其实就是最大化似然估计。为了方便表示和计算，我们通常会对似然函数取对数，将乘积转化为求和，然后在前面加上负号，将最大化问题转化为最小化问题，得到最终的目标函数：
                $$\theta^\ast = \arg\min_\theta -\sum_{i=1}^N \log p_\theta(y_i|x_i) \tag{5}$$ </p>
                <p>(2) 我们也可以选择去建模联合分布$p_\theta(x, y)$或者$p_\theta(x|y)p_\theta(y)$，然后通过贝叶斯公式得到条件分布$p(y|x)$:
                $$
                \begin{aligned}
                    p(y|x) &amp;= \frac{p(x, y)}{p(x)} \approx \frac{p_\theta(x, y)}{p(x)} \\
                    &amp;= \frac{p_\theta(x|y)p_\theta(y)}{p(x)}
                \end{aligned}
                \tag{6}
                $$
                这就是<strong>生成式模型（generative model）</strong>，它试图捕捉数据的生成过程。常见的生成式模型包括朴素贝叶斯、隐马尔可夫模型（HMM）、生成对抗网络（GAN）、变分自编码器（VAE）等。</p>
                <p>假设我们有一个训练集$\{(x_i, y_i)\}_{i=1}^N$，其中$x_i$是输入，$y_i$是对应的标签。假设数据是独立同分布的，对于整个数据集中的数据，预测时有：
                $$
                \arg\max_y p(y|x) \approx \arg\max_\theta \prod_{i=1}^N \frac{p_{\theta}(x_i|y_i)p_{\theta}(y_i)}{p(x)}
                \tag{7}
                $$
                由于$p(x)$与$y$无关，我们可以忽略它，得到：
                $$
                \arg\max_y p(y|x) \approx \arg\max_\theta \prod_{i=1}^N p_{\theta}(x_i|y_i)p_{\theta}(y_i) \tag{8}
                $$
                同样地，为了方便表示和计算，我们通常会对似然函数取对数，将乘积转化为求和，然后在前面加上负号，将最大化问题转化为最小化问题，得到最终的目标函数：
                $$
                \theta^\ast = \arg\min_\theta -\sum_{i=1}^N \left[\log p_\theta(x_i|y_i) + \log p_\theta(y_i) \right] \tag{9}
                $$</p>
                </section><section class="post-section" id="无监督学习"><h2 data-heading-id="无监督学习">无监督学习</h2>
                <p>对于无监督学习，数据通常只有输入$x$，没有对应的标签$y$：
                $$x \sim p(x) \tag{10}$$
                无监督学习的目标通常是<strong>理解数据的结构</strong>，比如聚类、降维、密度估计等。在这种情况下，生成式模型尤为重要，因为它们可以帮助我们理解数据的分布和生成过程。</p>
                <ul>
                <li>生成式模型直接建模数据的分布$p_\theta(x)$，通过最大化数据的似然函数来学习模型参数：
                $$\theta^\ast = \arg\min_\theta - \mathbb{E}_{x\sim p(x)}[\log p_\theta(x)] \tag{11}$$</li>
                <li>判别式模型在无监督学习中相对较少见，但也有一些应用，比如自编码器（autoencoder）可以看作是一种判别式模型，它通过学习输入数据的压缩表示来实现降维和特征提取：
                $$z = f_\theta(x), \quad \hat{x} = g_\phi(z) \tag{12}$$
                它的解码过程其实就是在直接建模$p_\phi(x|z)$，只不过这里的$z$不是从真实分布$p(x)$采样得到的，而是通过编码器$f_\theta(x)$得到的。</li>
                </ul>
                <p>总结来说，<strong>判别式模型关注于输入和输出之间的关系，而生成式模型关注于数据的生成过程和分布</strong>。在实际应用中，选择哪种模型取决于具体任务的需求和数据的可用性。</p>
                <p>在 AI 里我们总在说“学习”。如果把一切还原到最朴素的第一性原理，可以从一个假设开始：存在一个真实但未知的分布 $p^*$，我们看到的数据只是从 $p^*$ 里抽样出来的有限样本。接下来所有“判别式 / 生成式”的分歧，都不是玄学，而是一个很具体的选择：我到底要拟合 $p^*$ 的哪一部分？</p>
                </section><section class="post-section" id="1-从数据形态出发：有监督-vs-无监督"><h2 data-heading-id="1-从数据形态出发：有监督-vs-无监督">1. 从数据形态出发：有监督 vs 无监督</h2>
                <h3 id="11-有监督学习：你拿到的是-math118">1.1 有监督学习：你拿到的是 $(x,y)$</h3>
                <p>有监督数据以“输入-标签”对出现：$$(x,y)\sim p^*(x,y)$$最常见任务是：给定输入 $x$，预测标签 $y$。从概率论角度，预测最自然的规则是最大后验（MAP）：$$\hat y(x)=\arg\max_y p^*(y|x)$$直觉就是：看到 $x$ 之后，哪个 $y$ 最可能，就选哪个。关键问题来了：我们不知道 $p^*(y|x)$。于是我们要用模型去近似它——而“怎么近似”就是判别式与生成式分岔的起点。</p>
                <h3 id="12-无监督学习：你只有-math124">1.2 无监督学习：你只有 $x$</h3>
                <p>无监督数据只有输入：$$x\sim p^*(x)$$此时没有 $y$，所以“直接学 $p(y|x)$”这件事在目标层面就不成立。无监督更自然的目标是：建模数据分布本身 $p^*(x)$（密度估计 / 生成建模）。</p>
                </section><section class="post-section" id="2-有监督学习的两条路：判别式-vs-生成式"><h2 data-heading-id="2-有监督学习的两条路：判别式-vs-生成式">2. 有监督学习的两条路：判别式 vs 生成式</h2>
                <p>你可以把“判别式 / 生成式”理解为：在有监督学习里，我们要拟合 $p^*(x,y)$ 的不同“切面”。</p>
                <h3 id="21-判别式模型：直接建模-math129">2.1 判别式模型：直接建模 $p(y|x)$</h3>
                <p>判别式的选择是直接近似后验：$$p^*(y|x)\approx p_\theta(y|x)$$推断（预测）时只对 $y$ 做 $\arg\max$：$$\hat y(x)=\arg\max_y p_\theta(y|x)$$训练时（别把训练和预测混在一起）给定训练集 $\{(x_i,y_i)\}_{i=1}^N$，常用假设是 i.i.d.：$$\theta^*=\arg\max_\theta\prod_{i=1}^N p_\theta(y_i|x_i)$$取对数并转为最小化：$$\theta^*=\arg\min_\theta-\sum_{i=1}^N\log p_\theta(y_i|x_i)$$这就是交叉熵 / 负对数似然的第一性原理来源：让模型的条件分布更像真实的条件分布。判别式模型“判别”的本质：它专注于“为了把 $y$ 分对，我需要怎样的 $p(y|x)$ 或决策边界”，而不强求解释 $x$ 本身在世界里如何分布（即不显式建模 $p(x)$）。典型例子：逻辑回归、SVM（本质是学判别边界/打分函数）、CRF、各类监督神经网络分类器/回归器等。</p>
                <h3 id="22-生成式模型：建模-math137-或-math138">2.2 生成式模型：建模 $p(x,y)$ 或 $p(x|y)p(y)$</h3>
                <p>生成式的选择是拟合更“源头”的联合结构：$$p^*(x,y)\approx p_\theta(x,y)$$通常用链式分解写成：$$p_\theta(x,y)=p_\theta(x|y)p_\theta(y)$$关键点：贝叶斯不是“计算技巧”，而是结构恒等式。由条件概率定义可得：$$p_\theta(y|x)=\frac{p_\theta(x,y)}{p_\theta(x)}=\frac{p_\theta(x|y)p_\theta(y)}{p_\theta(x)}$$其中分母是模型自身的边缘分布（归一化项）：$$p_\theta(x)=\sum_{y'}p_\theta(x|y')p_\theta(y')$$这一步常被称为“贝叶斯公式”，但它本质上只是联合分布的两种写法，不是额外添加的技巧。推断（预测）时因为对固定的 $x$，$p_\theta(x)$ 与 $y$ 无关，所以：$$\hat y(x)=\arg\max_y p_\theta(x|y)p_\theta(y)$$你在朴素贝叶斯里看到的“每个类别算一遍，选最大的”，就是这句。训练时生成式通常最大化联合似然：$$\theta^*=\arg\max_\theta\prod_{i=1}^N p_\theta(x_i,y_i)=\arg\max_\theta\prod_{i=1}^N p_\theta(x_i|y_i)p_\theta(y_i)$$对应的最小化形式：$$\theta^*=\arg\min_\theta-\sum_{i=1}^N\left[\log p_\theta(x_i|y_i)+\log p_\theta(y_i)\right]$$生成式模型“生成”的本质：它不仅想分对 $y$，还想描述“如果真的是某个 $y$，$x$ 通常会长什么样”，因此能自然支持采样、缺失值处理、异常检测、半监督等能力。典型例子：朴素贝叶斯、GDA/LDA/QDA、HMM；现代生成式 AI（VAE、扩散、自回归语言模型）更常见的是建模 $p(x)$ 或条件生成的 $p(x|c)$。</p>
                <h3 id="23-一个常见误解：生成式“没有边界”？">2.3 一个常见误解：生成式“没有边界”？</h3>
                <p>生成式模型不直接学“边界”，但边界一定存在，因为分类决策就是比较两个量何时相等：$$p_\theta(x|y=1)p_\theta(y=1)=p_\theta(x|y=0)p_\theta(y=0)$$边界不是没有，而是“比较两个生成概率”自然诱导出来的。</p>
                </section><section class="post-section" id="3-为什么需要两条路？（motivation-的核心）"><h2 data-heading-id="3-为什么需要两条路？（motivation-的核心）">3. 为什么需要两条路？（motivation 的核心）</h2>
                <p>判别式和生成式的根本取舍可以用一句话概括：判别式把建模能力集中在 $p(y|x)$ 上，更直接服务预测；生成式把建模能力用在 $p(x,y)$ 或 $p(x|y)p(y)$ 上，更像在复刻数据机制。因此常见经验是：只关心预测性能、输入极复杂（图像/文本）时，判别式通常更直接；小数据、缺失特征、需要不确定性/可解释或希望用无标签数据结构时，生成式常更自然；需要“会生成”或“能补全”时，必须引入对 $p(x)$ 或 $p(x|y)$ 的刻画（生成式的强项）。</p>
                </section><section class="post-section" id="4-无监督学习：为什么生成式更“天然”？"><h2 data-heading-id="4-无监督学习：为什么生成式更“天然”？">4. 无监督学习：为什么生成式更“天然”？</h2>
                <p>无监督只有 $\{x_i\}_{i=1}^N$，最本源目标是让 $p_\theta(x)$ 接近 $p^*(x)$。最经典的第一性原理训练准则是最大似然：$$\theta^*=\arg\max_\theta\sum_{i=1}^N\log p_\theta(x_i)=\arg\min_\theta-\frac{1}{N}\sum_{i=1}^N\log p_\theta(x_i)$$这就是密度估计 / 生成建模的核心。注意：无监督不等于“没有判别式方法”。现代自监督（对比学习、掩码预测等）往往是不显式建模 $p(x)$ 的“判别式训练目标”，它们学的是表征 $f_\theta(x)$，而不是可计算的 $p_\theta(x)$。</p>
                </section><section class="post-section" id="5-隐变量、变分推断与-vae：生成式为什么会遇到“推断”？"><h2 data-heading-id="5-隐变量、变分推断与-vae：生成式为什么会遇到“推断”？">5. 隐变量、变分推断与 VAE：生成式为什么会遇到“推断”？</h2>
                <p>很多生成式模型会引入隐变量 $z$ 来表达潜在结构：$$p_\theta(x,z)=p(z)p_\theta(x|z)$$此时边缘似然是：$$p_\theta(x)=\int p(z)p_\theta(x|z)\,dz$$困难在于积分常常不可解，于是后验也不可解：$$p_\theta(z|x)=\frac{p_\theta(x,z)}{p_\theta(x)}$$这就是“生成式模型里推断（inference）很难”的根源：越像真实世界，边缘化越算不动。</p>
                <h3 id="51-变分推断（vi）：用可控的-math159-近似后验">5.1 变分推断（VI）：用可控的 $q_\phi(z|x)$ 近似后验</h3>
                <p>VI 选择一个近似后验 $q_\phi(z|x)$，并最大化证据下界（ELBO）：$$\log p_\theta(x)\ge\mathbb E_{q_\phi(z|x)}[\log p_\theta(x|z)]-\mathrm{KL}\left(q_\phi(z|x)||p(z)\right)$$直觉很清晰：第一项让生成结果更像数据（重构/似然项），第二项让隐变量分布不乱跑（贴近先验）。</p>
                <h3 id="52-vae：生成模型-变分推断（摊销）">5.2 VAE：生成模型 + 变分推断（摊销）</h3>
                <p>VAE 就是把 $q_\phi(z|x)$ 用 encoder 网络实现，把 $p_\theta(x|z)$ 用 decoder 实现，训练目标就是上面的 ELBO。</p>
                </section><section class="post-section" id="6-gan：为什么它“用判别器训练”，却仍然是生成范式？"><h2 data-heading-id="6-gan：为什么它“用判别器训练”，却仍然是生成范式？">6. GAN：为什么它“用判别器训练”，却仍然是生成范式？</h2>
                <p>GAN 的生成器 $G$ 把噪声 $z\sim p(z)$ 映射成样本 $x=G(z)$，从而诱导一个分布 $p_g(x)$。目标是让 $p_g(x)$ 接近真实分布 $p^*(x)$。经典对抗目标是：$$\min_G\max_D\ \mathbb E_{x\sim p^*}[\log D(x)]+\mathbb E_{z\sim p(z)}[\log(1-D(G(z)))]$$这里的 $D$ 确实是一个判别式网络（区分真/假），但它是训练信号源；GAN 的最终目标仍是匹配数据分布 $p(x)$，所以 GAN 整体是生成范式（隐式生成模型）。也因此，GAN 一般不显式给出可计算的 $p_\theta(x)$，它不是最大似然训练的典型代表，而是 likelihood-free / implicit 的生成路线。</p>
                </section><section class="post-section" id="7-判别式模型能做生成吗？"><h2 data-heading-id="7-判别式模型能做生成吗？">7. 判别式模型能做生成吗？</h2>
                <p>如果你只有一个判别器 $p_\theta(y|x)$，一般不能直接从真实意义的 $p(x)$ 或 $p(x|y)$ 采样，因为你缺少“像数据”的约束。但判别式模型可以参与生成，关键关系是：$$p(x|y)\propto p(y|x)p(x)$$含义是：$p(y|x)$ 提供“朝目标 $y$ 靠近”的偏好，$p(x)$ 提供“像真实数据”的先验约束。因此常见组合方式包括：先从某个生成先验采样，再用判别器筛选；classifier guidance：用 $\nabla_x\log p(y|x)$ 引导扩散采样；能量模型思路：把判别打分当能量定义 $p(x)\propto e^{-E(x)}$ 再采样。一句话总结：判别式模型本身不负责“像数据”，但可以作为“导向力”帮助生成模型“像你想要的”。</p>
                </section><section class="post-section" id="8-“生成模型”和“生成式模型”有什么区别？"><h2 data-heading-id="8-“生成模型”和“生成式模型”有什么区别？">8. “生成模型”和“生成式模型”有什么区别？</h2>
                <p>大多数语境下两者同义，都指 generative model（建模 $p(x)$ 或 $p(x,y)$ 并可采样）。需要避免的歧义主要在 GAN 场景：GAN 是生成式模型（整个框架），$G$ 是生成器（不要把生成器单独叫生成模型）。</p>
                </section><section class="post-section" id="9-一个简单的自检清单（帮助你快速定位概念）"><h2 data-heading-id="9-一个简单的自检清单（帮助你快速定位概念）">9. 一个简单的自检清单（帮助你快速定位概念）</h2>
                <p>当你面对一个新模型/新论文时，可以按这个顺序问自己：我最终关心的是预测 $y$，还是建模数据分布 $x$？它显式在学 $p_\theta(y|x)$ 吗？如果是，多半是判别式。它显式或隐式在学 $p_\theta(x)$ / $p_\theta(x,y)$ / $p_\theta(x|y)$ 吗？如果是，多半是生成式。它有隐变量 $z$ 且出现 $q_\phi(z|x)$、ELBO、KL？大概率是 VI/VAE 的生成式推断框架。它有 $G$ 和 $D$ 的对抗训练？GAN：判别器是工具，整体目标仍是生成分布匹配。</p>
                </section><section class="post-section" id="总结"><h2 data-heading-id="总结">总结</h2>
                <p>判别式与生成式的差异不是“是不是分类”，而是你选择拟合 $p^*$ 的哪个切面：判别式拟合 $p^*(y|x)$，专注于预测与决策边界；生成式拟合 $p^*(x,y)$ 或 $p^*(x)$，专注于数据机制，因此能生成、能补全、能做密度相关任务。从“数据形态（有监督/无监督）”出发，这两条路线就会非常自然地长出来。</p>
                <p>很多“判别式 vs 生成式”的解释一上来就抛结论：判别式学 $p(y|x)$，生成式学 $p(x,y)$。这句话虽然对，但初学者真正卡住的不是结论，而是两个更底层的问题：第一，为什么“学习”可以用概率分布来描述；第二，为什么同一个任务会出现两条路线。要把这两个问题讲清楚，我们需要从一个朴素但很强的假设开始：存在一个真实但未知的分布 $p^*$，我们拿到的数据只是从 $p^*$ 抽样得到的有限样本。</p>
                </section><section class="post-section" id="1-学习是什么：从“真实分布”到“经验分布”"><h2 data-heading-id="1-学习是什么：从“真实分布”到“经验分布”">1. 学习是什么：从“真实分布”到“经验分布”</h2>
                <p>先区分两件事：世界的规律和我们的数据。世界规律用 $p^*$ 表示，数据是从 $p^*$ 抽样得到的一组样本。假设我们拿到 $N$ 个样本 $\{u_i\}_{i=1}^N$（先不管 $u$ 是 $x$ 还是 $(x,y)$），一个最常见的工程假设是 i.i.d.：样本独立同分布。这意味着：数据集出现的概率可以写成 $$p^*(u_1,\dots,u_N)=\prod_{i=1}^N p^*(u_i)$$但我们并不知道 $p^*$，于是“学习”的本质就是：选择一个参数化分布族 $p_\theta$，让它尽可能接近 $p^*$，并用数据估计出最合适的参数 $\theta$。
                这里的“接近”需要一个准则。最经典的选择是最大似然（MLE）：让观测到的数据在模型下尽可能“合理”。其目标是 $$\theta^*=\arg\max_\theta \prod_{i=1}^N p_\theta(u_i)$$取对数得到等价形式 $$\theta^*=\arg\max_\theta \sum_{i=1}^N \log p_\theta(u_i)$$再乘上 $-1$ 变成最小化形式 $$\theta^*=\arg\min_\theta -\frac{1}{N}\sum_{i=1}^N \log p_\theta(u_i)$$这一步非常关键：它告诉你，很多你熟悉的损失函数，本质上都是 $-\log(\cdot)$ 的平均，只是 $p_\theta$ 的具体形式不同。
                为了把“有限样本的平均”与“真实分布的期望”连接起来，我们引入经验分布 $\hat p_N$（把质量平均分配到每个样本上）。那么 $$-\frac{1}{N}\sum_{i=1}^N \log p_\theta(u_i)=\mathbb E_{u\sim \hat p_N}\big[-\log p_\theta(u)\big]$$当 $N$ 足够大时，$\hat p_N$ 会接近 $p^*$，于是我们可以把目标理解为：最小化 $$\mathbb E_{u\sim p^*}\big[-\log p_\theta(u)\big]$$这其实就是交叉熵 $H(p^*,p_\theta)$。因此最大似然可以被解释为：在给定模型族时，让 $p_\theta$ 尽可能靠近 $p^*$（精确地说是最小化 $\mathrm{KL}(p^*||p_\theta)$，差一个与 $\theta$ 无关的常数）。</p>
                </section><section class="post-section" id="2-有监督与无监督：数据形态决定了你能学什么"><h2 data-heading-id="2-有监督与无监督：数据形态决定了你能学什么">2. 有监督与无监督：数据形态决定了你能学什么</h2>
                <p>现在把 $u$ 具体化。无监督学习只有输入 $x$：$$x\sim p^*(x)$$有监督学习拿到的是输入-标签对 $(x,y)$：$$(x,y)\sim p^*(x,y)$$两者的区别不是“是否高级”，而是目标对象不同。无监督里你最自然能做的是拟合 $p^*(x)$；有监督里你既可以拟合 $p^*(x,y)$，也可以只关心更贴近任务的 $p^*(y|x)$。这句话会在后面直接导出“生成式 vs 判别式”。</p>
                </section><section class="post-section" id="3-预测的第一性原理：为什么分类总能写成-map"><h2 data-heading-id="3-预测的第一性原理：为什么分类总能写成-map">3. 预测的第一性原理：为什么分类总能写成 MAP</h2>
                <p>在有监督学习里，我们最常见的任务是“给定 $x$ 预测 $y$”。从概率论角度，最自然的决策规则是最大后验（MAP）：$$\hat y(x)=\arg\max_y p^*(y|x)$$它的直觉非常朴素：看到 $x$ 后，哪个 $y$ 最可能，就选哪个。注意 MAP 是“预测规则”，不是“训练目标”。训练要做的是用数据学一个模型近似 $p^*(y|x)$ 或近似更源头的 $p^*(x,y)$，然后在推断阶段按上式做选择。
                到这里，分岔点出现：我们到底要学什么概率对象来服务 MAP？如果我们直接学 $p(y|x)$，这条路会导向判别式；如果我们先学 $p(x,y)$ 或 $p(x|y)p(y)$ 再推出 $p(y|x)$，这条路会导向生成式。下一篇我们先把“判别式”这条路从头推到交叉熵、logistic、softmax，把训练与推断彻底分清。</p>
                <p>上一节我们把“学习”还原成一个核心动作：用数据让 $p_\theta$ 接近真实分布 $p^*$。在有监督任务里，预测规则来自 MAP：$$\hat y(x)=\arg\max_y p^*(y|x)$$因此如果我们能学到一个好的 $p_\theta(y|x)$，就能直接替代 $p^*(y|x)$ 完成预测。这正是判别式模型的第一性原理。</p>
                </section><section class="post-section" id="1-判别式到底“建模什么”"><h2 data-heading-id="1-判别式到底“建模什么”">1. 判别式到底“建模什么”</h2>
                <p>判别式不是“能不能分类”的别名，而是一个很具体的选择：直接近似真实的条件分布 $$p^*(y|x)\approx p_\theta(y|x)$$因此判别式模型在推断阶段的动作很简单：$$\hat y(x)=\arg\max_y p_\theta(y|x)$$这里 $\arg\max$ 的对象是 $y$，这是预测；训练时 $\arg\max$ 的对象是 $\theta$，这是拟合模型，这两件事一定要分开写，否则初学者会在符号上被误导。</p>
                </section><section class="post-section" id="2-判别式的训练目标从哪里来：条件最大似然"><h2 data-heading-id="2-判别式的训练目标从哪里来：条件最大似然">2. 判别式的训练目标从哪里来：条件最大似然</h2>
                <p>给定训练集 $\{(x_i,y_i)\}_{i=1}^N$ 且假设 i.i.d.，判别式的最自然训练目标是条件最大似然：$$\theta^*=\arg\max_\theta \prod_{i=1}^N p_\theta(y_i|x_i)$$取对数并转成最小化：$$\theta^*=\arg\min_\theta -\sum_{i=1}^N \log p_\theta(y_i|x_i)$$这就是交叉熵损失的概率学来源：交叉熵不是拍脑袋的，它是“让条件分布贴近真实条件分布”的必然形式。
                如果 $y$ 是离散标签，且我们用 one-hot 表示真实分布，那么 $-\log p_\theta(y_i|x_i)$ 就是经典分类交叉熵；如果 $y$ 是连续值，选择不同的条件分布族（例如高斯），就会得到 MSE 等损失，这也是为什么“损失函数”本质上是“你假设了什么条件噪声模型”的体现。</p>
                </section><section class="post-section" id="3-logistic-回归与-softmax：判别式如何具体参数化-pyx"><h2 data-heading-id="3-logistic-回归与-softmax：判别式如何具体参数化-pyx">3. Logistic 回归与 Softmax：判别式如何具体参数化 p(y|x)</h2>
                <p>以二分类为例，logistic 回归把 $$p_\theta(y=1|x)=\sigma(w^Tx+b)$$其中 $\sigma(t)=\frac{1}{1+e^{-t}}$。这不是“玄学函数”，而是最简单的一种方式：把任意实数打分 $s=w^Tx+b$ 映射到 $[0,1]$，并且满足 $p(y=0|x)=1-p(y=1|x)$。
                多分类时，把每一类的打分记为 $s_k(x)$，用 softmax 参数化：$$p_\theta(y=k|x)=\frac{e^{s_k(x)}}{\sum_j e^{s_j(x)}}$$训练目标仍然是 $-\sum_i \log p_\theta(y_i|x_i)$，只是 $p_\theta$ 的形式变成 softmax。
                这一点很重要：判别式的核心不是“用神经网络”，而是“你直接建模的是条件分布 $p(y|x)$，所以训练就自然是条件最大似然”。</p>
                </section><section class="post-section" id="4-判别式为什么常被说“学边界”"><h2 data-heading-id="4-判别式为什么常被说“学边界”">4. 判别式为什么常被说“学边界”</h2>
                <p>在二分类里，决策边界可以写成 $$p_\theta(y=1|x)=p_\theta(y=0|x)$$对 logistic 来说，这等价于 $w^Tx+b=0$。因此判别式看起来像在“学一条边界”。但更本质的说法是：它在学习一个后验概率的形状，边界只是后验等值面的一个特例。</p>
                </section><section class="post-section" id="5-无监督里也有“判别式”：自监督的真正定位"><h2 data-heading-id="5-无监督里也有“判别式”：自监督的真正定位">5. 无监督里也有“判别式”：自监督的真正定位</h2>
                <p>很多人会说“无监督几乎都是生成式”。这在经典密度估计意义上成立，但现代自监督提供了一个非常重要的补充：你可以不显式建模 $p(x)$，而通过一个判别性任务学习表征 $f_\theta(x)$。例如对比学习的典型目标（InfoNCE）可以理解为：在一堆候选里判别哪一个是正样本，本质上是在学“区分规则”。它更像判别式训练目标，而不是可采样的 $p_\theta(x)$。
                因此更准确的二分是：生成式方法试图拟合 $p(x)$ 或 $p(x,y)$；判别式方法试图拟合 $p(y|x)$ 或学习一个直接服务决策的表征/打分函数。下一篇我们把生成式分类从 $p(x,y)$ 推到 $p(y|x)$，并把“贝叶斯到底是不是技巧”“生成式有没有边界”这些坑彻底填完。</p>
                <p>上一节我们走完了判别式路线：直接建模 $p(y|x)$，训练就是条件最大似然。现在我们换一条路：不直接学 $p(y|x)$，而是学更“源头”的联合结构 $p(x,y)$。这条路的第一性原理动机很简单：如果我不仅想分对 $y$，还想回答“数据 $x$ 在每个类别下通常长什么样”，那我就必须刻画 $x$ 的分布结构。</p>
                </section><section class="post-section" id="1-生成式到底“建模什么”"><h2 data-heading-id="1-生成式到底“建模什么”">1. 生成式到底“建模什么”</h2>
                <p>生成式的核心选择是：拟合联合分布 $$p^*(x,y)\approx p_\theta(x,y)$$通常用链式分解写成 $$p_\theta(x,y)=p_\theta(x|y)p_\theta(y)$$这不是“为了计算才这么写”，而是联合分布的基本分解方式。由条件概率定义可得 $$p_\theta(y|x)=\frac{p_\theta(x,y)}{p_\theta(x)}=\frac{p_\theta(x|y)p_\theta(y)}{p_\theta(x)}$$其中 $$p_\theta(x)=\sum_{y'}p_\theta(x|y')p_\theta(y')$$这一组等式经常被称为“贝叶斯公式”，但从第一性原理看，它只是“条件概率定义 + 联合分解”的恒等式，不是额外添加的技巧。</p>
                </section><section class="post-section" id="2-生成式如何做分类：map-变成比较-pxypy"><h2 data-heading-id="2-生成式如何做分类：map-变成比较-pxypy">2. 生成式如何做分类：MAP 变成比较 p(x|y)p(y)</h2>
                <p>分类的 MAP 规则是 $$\hat y(x)=\arg\max_y p_\theta(y|x)$$代入上式并注意对固定的 $x$，$p_\theta(x)$ 与 $y$ 无关，于是 $$\hat y(x)=\arg\max_y p_\theta(x|y)p_\theta(y)$$你在朴素贝叶斯里看到的“每个类别算一遍，选最大的”，就是这句的直接实现。</p>
                </section><section class="post-section" id="3-生成式的训练目标：最大化联合似然"><h2 data-heading-id="3-生成式的训练目标：最大化联合似然">3. 生成式的训练目标：最大化联合似然</h2>
                <p>给定训练集 $\{(x_i,y_i)\}_{i=1}^N$，生成式的自然训练目标是最大化联合似然：$$\theta^*=\arg\max_\theta \prod_{i=1}^N p_\theta(x_i,y_i)$$利用分解 $$p_\theta(x_i,y_i)=p_\theta(x_i|y_i)p_\theta(y_i)$$得到 $$\theta^*=\arg\max_\theta \prod_{i=1}^N p_\theta(x_i|y_i)p_\theta(y_i)$$转成最小化形式 $$\theta^*=\arg\min_\theta -\sum_{i=1}^N\left[\log p_\theta(x_i|y_i)+\log p_\theta(y_i)\right]$$这一步让你看到生成式与判别式训练的根本差别：判别式只拟合 $p(y|x)$；生成式拟合 $p(x|y)$ 与 $p(y)$，因此它要“解释输入 $x$ 的分布形状”。</p>
                </section><section class="post-section" id="4-生成式“有没有边界”：边界是诱导出来的"><h2 data-heading-id="4-生成式“有没有边界”：边界是诱导出来的">4. 生成式“有没有边界”：边界是诱导出来的</h2>
                <p>生成式不直接学边界，但边界一定存在。二分类时决策翻转发生在两类得分相等：$$p_\theta(x|y=1)p_\theta(y=1)=p_\theta(x|y=0)p_\theta(y=0)$$因此“没有边界”是一个视觉误解。更准确的说法是：生成式模型先学分布，边界是比较分布后自然长出来的等值面。</p>
                </section><section class="post-section" id="5-naive-bayes：用条件独立换取可估计性"><h2 data-heading-id="5-naive-bayes：用条件独立换取可估计性">5. Naive Bayes：用条件独立换取可估计性</h2>
                <p>朴素贝叶斯的关键假设是给定类别 $y$ 后各特征条件独立：如果 $x=(x_1,\dots,x_d)$，则 $$p(x|y)=\prod_{j=1}^d p(x_j|y)$$于是分类规则变成 $$\hat y(x)=\arg\max_y p(y)\prod_{j=1}^d p(x_j|y)$$这解释了它在小数据、稀疏高维（例如文本词袋）场景下常常很好用：你用一个强假设大幅减少了参数量，让 $p(x|y)$ 可估计。</p>
                </section><section class="post-section" id="6-高斯判别分析：ldaqda-与“边界形状”的来源"><h2 data-heading-id="6-高斯判别分析：ldaqda-与“边界形状”的来源">6. 高斯判别分析：LDA/QDA 与“边界形状”的来源</h2>
                <p>另一个经典生成式分类框架是假设每个类别下 $x$ 服从高斯分布。对类 $k$：$$p(x|y=k)=\mathcal N(x;\mu_k,\Sigma_k)$$如果进一步假设所有类别共享协方差 $\Sigma_k=\Sigma$，得到 LDA；如果允许每类不同协方差，得到 QDA。
                用 MAP 规则比较 $$\log p(x|y=k)+\log p(y=k)$$就能推导出：LDA 的边界是线性的，QDA 的边界是二次的。这里的“线性/二次”不是拍脑袋选的，而是高斯对数密度天然带来的形状。</p>
                </section><section class="post-section" id="7-生成式与判别式的关系：同一个目标，不同的拟合切面"><h2 data-heading-id="7-生成式与判别式的关系：同一个目标，不同的拟合切面">7. 生成式与判别式的关系：同一个目标，不同的拟合切面</h2>
                <p>你会发现：推断时两者都可以写成 $$\hat y(x)=\arg\max_y p(y|x)$$差别完全来自“训练时你拟合了什么”。生成式拟合联合结构，往往在小数据或缺失特征时更稳；判别式直接拟合后验，往往在高维复杂输入、数据充足时更强。这不是口号，而是“参数化对象不同导致的样本效率与偏差-方差权衡”。
                下一篇我们转到无监督：为什么无监督天然会走向 $p(x)$，为什么引入隐变量 $z$ 会立刻遇到“推断算不动”，以及 VI/ELBO/VAE 怎么从第一性原理推出。</p>
                <p>无监督学习只有 $x$：$$x\sim p^*(x)$$没有标签 $y$，所以“直接学 $p(y|x)$”在目标层面就不成立。无监督最自然的第一性原理目标是：拟合数据分布本身 $$p^*(x)\approx p_\theta(x)$$并用最大似然训练：$$\theta^*=\arg\max_\theta \sum_{i=1}^N \log p_\theta(x_i)=\arg\min_\theta -\frac{1}{N}\sum_{i=1}^N \log p_\theta(x_i)$$这就是密度估计的核心。</p>
                </section><section class="post-section" id="1-为什么要引入隐变量-z：用结构换可表达性"><h2 data-heading-id="1-为什么要引入隐变量-z：用结构换可表达性">1. 为什么要引入隐变量 z：用结构换可表达性</h2>
                <p>直接写一个足够强的 $p_\theta(x)$ 有时很难，于是引入隐变量 $z$ 表达潜在因素：$$p_\theta(x,z)=p(z)p_\theta(x|z)$$边缘分布是 $$p_\theta(x)=\int p(z)p_\theta(x|z)\,dz$$这一步的动机很朴素：很多复杂分布可以通过“先采样一个低维结构变量 $z$，再由 $z$ 生成 $x$”来表达。</p>
                </section><section class="post-section" id="2-生成式的核心困难：边缘化与后验不可解"><h2 data-heading-id="2-生成式的核心困难：边缘化与后验不可解">2. 生成式的核心困难：边缘化与后验不可解</h2>
                <p>一旦引入 $z$，你马上遇到两个“算不动”：第一，边缘似然 $$\log p_\theta(x)=\log \int p(z)p_\theta(x|z)\,dz$$第二，后验推断 $$p_\theta(z|x)=\frac{p(z)p_\theta(x|z)}{p_\theta(x)}$$分母 $p_\theta(x)$ 正是上面算不动的积分，所以后验也算不动。这就是为什么生成式建模会天然把你带到“推断”问题上：你越想让模型像真实生成过程，边缘化越难。</p>
                </section><section class="post-section" id="3-变分推断的第一性原理：用-qzx-逼近-pzx"><h2 data-heading-id="3-变分推断的第一性原理：用-qzx-逼近-pzx">3. 变分推断的第一性原理：用 q(z|x) 逼近 p(z|x)</h2>
                <p>变分推断的核心动作是引入一个可控分布族 $q_\phi(z|x)$ 去近似真实后验 $p_\theta(z|x)$。从恒等变形开始：$$\log p_\theta(x)=\log \int p_\theta(x,z)\,dz=\log \int q_\phi(z|x)\frac{p_\theta(x,z)}{q_\phi(z|x)}\,dz$$对 $\log$ 用 Jensen 不等式得到下界：$$\log p_\theta(x)\ge \mathbb E_{q_\phi(z|x)}\left[\log p_\theta(x,z)-\log q_\phi(z|x)\right]$$把 $p_\theta(x,z)=p(z)p_\theta(x|z)$ 展开：$$\log p_\theta(x)\ge \mathbb E_{q_\phi(z|x)}[\log p_\theta(x|z)]-\mathrm{KL}\left(q_\phi(z|x)||p(z)\right)$$这就是 ELBO。它的直觉非常明确：第一项让重构更好（更像数据），第二项把 $q_\phi(z|x)$ 拉回先验 $p(z)$（防止 $z$ 乱跑）。
                还有一个更“结构化”的恒等式值得记住：$$\log p_\theta(x)=\mathrm{ELBO}(x)+\mathrm{KL}\left(q_\phi(z|x)||p_\theta(z|x)\right)$$因为 KL 非负，所以 ELBO 是下界；最大化 ELBO 等价于让近似后验贴近真实后验。</p>
                </section><section class="post-section" id="4-vae：把-vi-变成可训练的神经网络系统"><h2 data-heading-id="4-vae：把-vi-变成可训练的神经网络系统">4. VAE：把 VI 变成可训练的神经网络系统</h2>
                <p>VAE 就是在做两件事：用 encoder 实现 $q_\phi(z|x)$，用 decoder 实现 $p_\theta(x|z)$，并最大化 ELBO：$$\max_{\theta,\phi}\ \mathbb E_{q_\phi(z|x)}[\log p_\theta(x|z)]-\mathrm{KL}\left(q_\phi(z|x)||p(z)\right)$$为了让梯度能穿过采样，VAE 通常用重参数技巧：若 $q_\phi(z|x)=\mathcal N(\mu_\phi(x),\Sigma_\phi(x))$，则可写成 $z=\mu_\phi(x)+\Sigma_\phi(x)^{1/2}\epsilon$，其中 $\epsilon\sim\mathcal N(0,I)$。这样采样的随机性被移到 $\epsilon$ 上，$\phi$ 可以通过 $\mu,\Sigma$ 反传。</p>
                </section><section class="post-section" id="5-ae-与-vae：为什么“重构”不等于“生成建模”"><h2 data-heading-id="5-ae-与-vae：为什么“重构”不等于“生成建模”">5. AE 与 VAE：为什么“重构”不等于“生成建模”</h2>
                <p>很多初学者会把 autoencoder 当成生成模型，因为它也能重构 $x$。但经典 AE 通常只优化重构误差 $$\min_{\theta,\phi}\ \sum_i \|x_i-g_\phi(f_\theta(x_i))\|^2$$它并没有明确的先验 $p(z)$，也没有对应的 $p_\theta(x)$ 的似然解释，因此严格意义上它不等价于可采样的生成分布。VAE 的关键就在于：它把 $z$ 变成随机变量，并通过 $p(z)$ 与 KL 项把“重构系统”升级为“概率生成模型”。
                下一篇我们讲 GAN 这条 likelihood-free 路线：为什么它有判别器却仍是生成范式，最优判别器对应什么，GAN 与“判别式能不能生成”怎么连起来，以及 classifier guidance、能量模型这类把判别与生成组合的方式。</p>
                <p>在前几篇里，生成式建模常常意味着你能写出一个显式的 $p_\theta(x)$ 并做最大似然。但 GAN 提供了另一条路：你可以不显式写出可计算的 $p_\theta(x)$，而是用一个采样过程定义一个“隐式分布” $p_g(x)$，再用对抗训练逼近真实分布 $p^*(x)$。这就是为什么 GAN 往往被称为 implicit 或 likelihood-free 的生成路线。</p>
                </section><section class="post-section" id="1-gan-的第一性原理目标：匹配-px"><h2 data-heading-id="1-gan-的第一性原理目标：匹配-px">1. GAN 的第一性原理目标：匹配 p(x)</h2>
                <p>GAN 的生成器 $G$ 把噪声 $z\sim p(z)$ 映射为 $x=G(z)$，从而诱导一个分布 $p_g(x)$。训练目标是让 $$p_g(x)\approx p^*(x)$$注意这里我们并没有给出 $p_g(x)$ 的解析式，我们只知道如何采样。这就是“隐式生成”的含义。
                经典 GAN 引入判别器 $D(x)$ 做真伪二分类，对抗目标是 $$\min_G\max_D\ \mathbb E_{x\sim p^*}[\log D(x)]+\mathbb E_{z\sim p(z)}[\log(1-D(G(z)))]$$</p>
                </section><section class="post-section" id="2-判别器是判别式网络，但-gan-仍是生成范式"><h2 data-heading-id="2-判别器是判别式网络，但-gan-仍是生成范式">2. 判别器是判别式网络，但 GAN 仍是生成范式</h2>
                <p>$D$ 的任务确实是判别式的：它在学 $p(\text{real}|x)$。但 GAN 的最终目标不是拿 $D$ 做分类，而是利用 $D$ 提供的梯度让 $G$ 改变 $p_g(x)$ 去逼近 $p^*(x)$。因此结论很清晰：GAN 里有判别器不等于 GAN 是判别式模型；GAN 的建模对象仍然是数据分布 $p(x)$，所以它属于生成范式。</p>
                </section><section class="post-section" id="3-最优判别器在干什么：密度比"><h2 data-heading-id="3-最优判别器在干什么：密度比">3. 最优判别器在干什么：密度比</h2>
                <p>固定 $G$ 时，最优判别器可以写成 $$D^*(x)=\frac{p^*(x)}{p^*(x)+p_g(x)}$$这说明 $D$ 在估计一个密度比结构，从而给 $G$ 指出“真实区域与生成区域哪里不一致”。因此对抗训练可以理解为“用判别器间接比较两个分布并驱动它们靠近”。</p>
                </section><section class="post-section" id="4-判别式模型能不能生成：缺的是-px"><h2 data-heading-id="4-判别式模型能不能生成：缺的是-px">4. 判别式模型能不能生成：缺的是 p(x)</h2>
                <p>现在回到你之前最关心的问题之一：判别式模型能做生成吗？如果你只有 $p_\theta(y|x)$，通常不能直接从 $p(x)$ 或 $p(x|y)$ 采样，因为你没有“像数据”的先验约束。你可以做 $$x^*=\arg\max_x p_\theta(y|x)$$但这往往会得到“让分类器极其自信但不像真实数据”的样本，本质原因是：你只优化了“符合标签”的方向，没有约束“像真实分布”的方向。
                关键桥梁是这句：$$p(x|y)\propto p(y|x)p(x)$$含义是：如果你想从目标类 $y$ 的条件分布采样，你必须同时拥有两部分信息：$p(y|x)$ 告诉你“什么样的 $x$ 更像 $y$”，$p(x)$ 告诉你“什么样的 $x$ 像真实数据”。判别式单独缺的就是 $p(x)$。</p>
                </section><section class="post-section" id="5-判别式如何参与生成：三种典型方式"><h2 data-heading-id="5-判别式如何参与生成：三种典型方式">5. 判别式如何参与生成：三种典型方式</h2>
                <p>第一种方式是筛选：先从某个生成先验 $p(x)$ 采样很多候选，再用 $p(y|x)$ 选高分样本。这简单但低效。
                第二种方式是引导：如果你已经有一个生成过程在近似采样 $p(x)$，你可以用 $\nabla_x\log p(y|x)$ 作为“导向力”把采样轨迹推向目标条件，这就是 classifier guidance 的核心思想。它的直觉与上式一致：生成模型保证“像数据”，分类器保证“像目标”。
                第三种方式是能量模型视角：把一个打分函数当作能量 $E_\theta(x)$，定义 $$p_\theta(x)\propto e^{-E_\theta(x)}$$再用 Langevin 等采样方法生成。这类方法常常用判别性训练学到能量，但最终仍然定义了一个生成分布。</p>
                </section><section class="post-section" id="6-术语澄清：生成模型-vs-生成式模型"><h2 data-heading-id="6-术语澄清：生成模型-vs-生成式模型">6. 术语澄清：生成模型 vs 生成式模型</h2>
                <p>大多数语境下“生成模型”和“生成式模型”同义，都指 generative modeling，建模对象是 $p(x)$ 或 $p(x,y)$ 并可采样。最常见的歧义出现在 GAN：GAN 是生成式模型（整体框架），$G$ 是生成器（组件），不要把生成器单独叫生成模型。
                到这里，你可以把整套体系收束成一个统一视角：判别式的建模对象是 $p(y|x)$，生成式的建模对象是 $p(x)$ 或 $p(x,y)$；有监督下两者都可服务 MAP，但拟合切面不同；无监督下 $p(x)$ 是主角，因此生成式更天然；VAE 用 VI/ELBO 解决“隐变量后验算不动”；GAN 用对抗绕开显式似然；判别式若想生成，必须与某种 $p(x)$ 形式结合。</p></section>
                </div>

                <div data-component="post-navigation"></div>
            </article>
        </div>

        <div data-include="../partials/sidebar-post.html"></div>
    </main>

    <div data-include="../partials/footer.html"></div>
    </div><!-- end page-container -->

    <script src="../script.js"></script>
</body>

</html>
