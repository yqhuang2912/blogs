<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>从策略梯度到REINFORCE算法 | 科学空间</title>
    <link rel="stylesheet" href="../styles.css">

    <script type="application/json" id="post-metadata">
        {
            "id": "11390",
            "slug": "policy-gradient",
            "title": "从策略梯度到REINFORCE算法",
            "createdAt": "2025-11-11",
            "day": "11",
            "month": "Nov",
            "categories": [
                "技术分享"
            ],
            "tags": [
                "数学推导",
                "强化学习"
            ],
            "summary": [],
            "link": "posts/policy-gradient.html"
        }
    </script>

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>

<body>
    <div class="page-container">
        <div data-include="../partials/navbar.html"></div>

    <main class="main-content">
        <div class="wrapper">
            <article class="post">
                <div data-component="post-header"
                     data-day="11"
                     data-month="Nov"
                     data-title="从策略梯度到REINFORCE算法"
                     data-link=""
                     data-meta="&lt;span class=&quot;meta-item meta-date&quot;&gt;2025-11-11&lt;/span&gt;&lt;span class=&quot;meta-divider&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;meta-item meta-categories&quot;&gt;分类：&lt;a href=&quot;#&quot;&gt;技术分享&lt;/a&gt;&lt;/span&gt;&lt;span class=&quot;meta-divider&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;meta-item meta-tags&quot;&gt;标签：&lt;a href=&quot;#&quot;&gt;数学推导&lt;/a&gt;,&lt;a href=&quot;#&quot;&gt;强化学习&lt;/a&gt;&lt;/span&gt;"
                     data-heading="h1"
                     data-meta-class="post-meta"
                     data-title-class="post-title"></div>

                <div class="post-content single-post-content">
                <p>基于策略的强化学习(Policy-based RL)算法的核心目标是找到一个好的策略，Agent使用这个“好策略”和环境交互的时候可以得到环境给与的最大回报。这个问题可以建模为：
                $$J(\theta) = \mathbb{E}_{\tau \sim P_{\theta}(\tau)}[R(\tau)]$$
                其中:</p>
                <ul>
                <li>$\tau$是一条轨迹，是状态$s$，动作$a$和即时奖励$r$的集合$\{s_0,a_0,r_0,s_1,a_1,r_1,\cdots,s_n\}$</li>
                <li>$P_{\theta}(\tau)$是Agent所能运行的所有可能的轨迹；</li>
                <li>$R(\tau)$是Agent在环境中按照轨迹$\tau$运行完所得到的累积回报。</li>
                </ul>
                </div>

                <div data-component="post-navigation"></div>
            </article>
        </div>

        <div data-include="../partials/sidebar-post.html"></div>
    </main>

    <div data-include="../partials/footer.html"></div>
    </div><!-- end page-container -->

    <script src="../script.js"></script>
</body>

</html>
