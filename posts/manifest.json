{
  "generatedAt": "2025-12-03T06:32:42.911Z",
  "postCount": 13,
  "posts": [
    {
      "id": "11400",
      "slug": "probability-and-likelihood",
      "title": "概率和似然",
      "createdAt": "2025-12-03",
      "day": "3",
      "month": "Dec",
      "categories": [
        "数学研究"
      ],
      "tags": [
        "概率分布",
        "极大似然"
      ],
      "summary": [
        {
          "type": "p",
          "html": "在概率论中，概率（Probability）和似然（Likelihood）是两个相关但是完全不同的概念。理解它们的区别对于统计推断和机器学习等领域非常重要。"
        },
        {
          "type": "h2",
          "html": "概率和似然"
        },
        {
          "type": "ul",
          "html": "<ul><li><p><strong>概率</strong>：描述的是<strong>在已知模型参数$\\theta$的情况下，观察到某个数据$D$的可能性</strong>。例如：已知一枚硬币是公平的（这里的公平指的是正常的，没有被动过手脚的），那么抛一枚硬币，得到正面正面朝上的概率是就是$p(正面朝上|硬币公平)=0.5$。这里说的<u>模型的参数已知可以理解为投掷硬币的概率分布$P_\\theta$是已知的</u>。概率的公式为：\n                $$p(D|\\theta),\\theta=\\begin{cases}0.5 &amp; D=正面朝上 \\\\ 0.5 &amp; D=反面朝上 \\end{cases} \\tag{1}$$\n                其中，$D$表示观察到的数据，$\\theta$表示模型的参数。那么，在已知$\\theta$的情况下，我们可以计算抛10次硬币，得到7次正面朝上的概率为：\n                $$p(D|\\theta) = \\binom{10}{7} (0.5)^7 (0.5)^3 \\tag{2}$$</p>\n                </li>\n                <li><p><strong>似然</strong>：描述的是<strong>在已知数据$D$的情况下，模型参数$\\theta$取某个值的可能性</strong>。例如：假设我们抛了一枚硬币10次，结果得到7次正面朝上，3次反面朝上。那么，我们想知道这枚硬币是公平的（$\\theta=0.5$）的可能性有多大，或者偏向正面朝上的（$\\theta&gt;0.5$）的可能性更大。计算的方式为：\n                $$\\mathcal{L}(\\theta|7正面,3反面) = \\binom{10}{7} \\theta^7 (1-\\theta)^3 \\tag{3}$$</p>\n                </li></ul>"
        }
      ],
      "link": "posts/probability-and-likelihood.html",
      "metaText": "2025-12-03 | 分类：数学研究 | 标签：概率分布,极大似然"
    },
    {
      "id": "11399",
      "slug": "distribution",
      "title": "分布到底是什么？",
      "createdAt": "2025-12-01",
      "day": "1",
      "month": "Dec",
      "categories": [
        "数学研究"
      ],
      "tags": [
        "概率分布"
      ],
      "summary": [
        {
          "type": "p",
          "html": "平时经常会听到“这个东西服从某个分布”，也听说过“高斯分布”，“泊松分布”等，但一直没有仔细思考过“分布”到底是什么。"
        },
        {
          "type": "ul",
          "html": "<ul><li>分布到底是个什么对象？是一条曲线？一张图？还是一堆参数？</li>\n                <li>我手上只有数据点，分布在哪里？</li>\n                <li>为什么同样叫分布，有时候是$p(x)$，有时候是$P(x)$，有时候是$F(x)$？</li></ul>"
        },
        {
          "type": "p",
          "html": "要弄清楚这些，得先从一些基本概念开始。"
        },
        {
          "type": "h2",
          "html": "一些基本概念"
        },
        {
          "type": "figure",
          "html": "<figure><img src=\"../assets/11399/sample-space-event-variables.png\" alt=\"sample-space-event-variables\" width=\"400\">\n                <figcaption>图1：一些基本概念的可视化</figcaption></figure>"
        }
      ],
      "link": "posts/distribution.html",
      "metaText": "2025-12-01 | 分类：数学研究 | 标签：概率分布"
    },
    {
      "id": "11398",
      "slug": "llm-temperature-topp",
      "title": "大模型输出的随机性和多样性",
      "createdAt": "2025-11-30",
      "day": "30",
      "month": "Nov",
      "categories": [
        "人工智能"
      ],
      "tags": [
        "大模型",
        "技术分享"
      ],
      "summary": [
        {
          "type": "p",
          "html": "我们在调用大模型时，通常会设置两个参数：Temperature和Top-p。我们上网一查，都会说这两个参数可以控制大模型输出的随机性和多样性。但是，关于这两个参数的细节一直没有去了解，今天看了一个<a href=\"https://www.bilibili.com/video/BV1taSFBNEG4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=af1e89d4624a6f02ed73e2312d492273\">视频</a>，才对这两个参数为什么会影响大模型输出的随机性和多样性有了比较详细的了解，这里记录一下。"
        },
        {
          "type": "h2",
          "html": "大模型是怎么输出的？"
        },
        {
          "type": "p",
          "html": "目前主流的大模型都是使用Next-Token-Prediction (NTP)这种范式，其本质上是给定前面的tokens，预测下一个token的条件概率分布：\n                $$\n                P(t_i|t_{&lt;i})=\\text{softmax}(\\mathbf{z}_i) \\tag{1}\n                $$\n                其中，$\\mathbf{z}_i=\\text{LLM}_{\\theta}(t_{&lt;i}) \\in \\mathbb{R}^{|V|}$是第$i$步输出的logits，$t_{&lt;i}$是前面的tokens，$P(t_i|t_{&lt;i})$是$t_i$给定$t_{&lt;i}$的条件概率，$\\theta$是模型的参数，$|V|$是词表的大小。"
        },
        {
          "type": "p",
          "html": "这其实是一个分类问题，我们假设整个Vocabulary（即所有可能的token）是$V$，那么大模型在第$i$步做的事情就是依据前面的$i-1$个token，从$V$中选择一个token作为第$i$个token的预测。"
        }
      ],
      "link": "posts/llm-temperature-topp.html",
      "metaText": "2025-11-30 | 分类：人工智能 | 标签：大模型,技术分享"
    },
    {
      "id": "11397",
      "slug": "low-dose-simulation",
      "title": "低剂量CT图像的噪声模拟",
      "createdAt": "2025-11-20",
      "day": "20",
      "month": "Nov",
      "categories": [
        "计算成像"
      ],
      "tags": [
        "CT成像",
        "泊松噪声"
      ],
      "summary": [
        {
          "type": "p",
          "html": "在医学成像中，低剂量CT（Computed\r\n                            Tomography）扫描是一种常用的技术，旨在减少患者接受的辐射剂量。然而，降低辐射剂量通常会导致图像质量下降，主要表现为噪声增加。为了研究和改进低剂量CT图像的处理方法，我们需要模拟低剂量CT图像中的噪声特性。"
        },
        {
          "type": "h2",
          "html": "光子计数的泊松分布模拟"
        },
        {
          "type": "p",
          "html": "从上一篇文章《<a href=\"./posts/ct-proj-and-poisson.html\">CT投影和泊松噪声的关系</a>》中，我们知道，在理想的、无噪声的世界里，X\r\n                                射线穿过物体遵循 Beer-Lambert 定律:\r\n                                $$N = N_0 \\cdot e^{-\\mu l} = N_0 \\cdot e^{-p_{\\text{ICT}}} \\tag{1}$$\r\n                                其中，$N_0$是入射到物体上的 X 射线光子数，$N$是穿过物体后到达探测器的 X\r\n                                射线光子数，$\\mu$是物体的线性衰减系数，$l$是射线穿过物体的路径长度，$p_{\\text{ICT}}$是<strong>理想线积分值</strong>(True Line\r\n                                Integral)，也即CT的投影值，这是我们想要测量的物理量，则:\r\n                                $$p_{\\text{ICT}} = -\\ln\\left(\\frac{N}{N_0}\\right) \\tag{2}$$"
        },
        {
          "type": "p",
          "html": "在现实世界中，光子的发射和探测是一个随机过程。即$N$不再是一个确定值，而是一个服从泊松分布的随机变量:\r\n                                $$N \\sim \\text{Poisson}(N_0 \\cdot e^{-p_{\\text{ICT}}}) \\tag{3}$$"
        }
      ],
      "link": "posts/low-dose-simulation.html",
      "metaText": "2025-11-20 | 分类：计算成像 | 标签：CT成像,泊松噪声"
    },
    {
      "id": "11396",
      "slug": "ct-proj-and-poisson",
      "title": "CT投影和泊松噪声的关系",
      "createdAt": "2025-11-19",
      "day": "19",
      "month": "Nov",
      "categories": [
        "计算成像"
      ],
      "tags": [
        "CT成像",
        "泊松噪声"
      ],
      "summary": [
        {
          "type": "h2",
          "html": "理想CT图像的投影"
        },
        {
          "type": "p",
          "html": "CT的成像是通过探测X射线在人体内的衰减来实现的。因为人体的不同组织对X射线的衰减系数不同，所以如果我们能够测量出不同组织对X射线的衰减系数，也就相当于得到了人体内部的结构信息。"
        },
        {
          "type": "p",
          "html": "如图1所示，我们假设入射光的强度为$I_0$，经过一个均匀分布的测量物体后探测到的光强为$I$，那么根据<a href=\"https://zh.wikipedia.org/wiki/%E6%AF%94%E5%B0%94-%E6%9C%97%E4%BC%AF%E5%AE%9A%E5%BE%8B\">Beer-Lambert定律</a>，X射线衰减后所具有的光强可以表示为：\r\n                $$I = I_0 \\cdot e^{-\\mu l} \\tag{1}$$\r\n                其中，$\\mu$是物体的线性衰减系数，$l$表示射线穿过物体的直线长度。"
        },
        {
          "type": "figure",
          "html": "<figure><img src=\"../assets/11396/beer_lambert.png\" alt=\"X 射线穿过单个均匀介质示意图\" ,=\"\" width=\"200\">\r\n                  <figcaption>图1 X 射线穿过单个均匀介质示意图</figcaption></figure>"
        }
      ],
      "link": "posts/ct-proj-and-poisson.html",
      "metaText": "2025-11-19 | 分类：计算成像 | 标签：CT成像,泊松噪声"
    },
    {
      "id": "11395",
      "slug": "ct-window",
      "title": "CT图像窗宽与窗位",
      "createdAt": "2025-11-18",
      "day": "18",
      "month": "Nov",
      "categories": [
        "计算成像"
      ],
      "tags": [
        "图像处理"
      ],
      "summary": [
        {
          "type": "p",
          "html": "在医学CT图像处理中，窗宽（Window Width, WW）和窗位（Window Level,\r\n                            WL）是两个非常重要的参数，用于调整图像的对比度和亮度，从而更好地显示不同组织结构的细节。"
        },
        {
          "type": "h2",
          "html": "窗宽与窗位的定义"
        },
        {
          "type": "ul",
          "html": "<ul><li>窗宽（WW）：表示CT图像中灰度级别的范围。较大的窗宽可以显示更多的灰度级别，适用于显示密度差异较大的组织（如肺部）；较小的窗宽则适用于显示密度差异较小的组织（如脑组织）。\r\n                                </li>\r\n                                <li>窗位（WL）：表示CT图像灰度级别的中心值。通过调整窗位，可以改变图像的亮度，使得特定密度范围内的组织更加清晰可见。</li></ul>"
        },
        {
          "type": "figure",
          "html": "<figure><img src=\"../assets/11395/ct_window.png\" alt=\"CT图像窗宽与窗位示意图\" ,=\"\" width=\"360\">\r\n                                <figcaption>CT图像窗宽与窗位示意图</figcaption></figure>"
        }
      ],
      "link": "posts/ct-window.html",
      "metaText": "2025-11-18 | 分类：计算成像 | 标签：图像处理"
    },
    {
      "id": "11394",
      "slug": "dicom-image",
      "title": "DICOM图像处理",
      "createdAt": "2025-11-18",
      "day": "18",
      "month": "Nov",
      "categories": [
        "计算成像"
      ],
      "tags": [
        "DICOM",
        "图像处理"
      ],
      "summary": [
        {
          "type": "p",
          "html": "DICOM（<u>D</u>igital <u>I</u>maging and <u>CO</u>mmunications in\r\n                            <u>M</u>edicine）是一种用于存储和传输医学影像的标准格式。DICOM文件由图像数据和头文件组成，图像数据是二维或三维的像素矩阵，头文件包含丰富的元数据信息，比如患者信息、扫描设备的信息，扫描参数等。下面以Mayo2016数据集中的DICOM图像为例，介绍如何进行基本的DICOM图像处理。"
        },
        {
          "type": "h2",
          "html": "读取DICOM图像"
        },
        {
          "type": "p",
          "html": "我们可以使用Python的pydicom库来读取DICOM文件。以下是一个简单的示例代码："
        },
        {
          "type": "pre",
          "html": "<pre><code class=\"language-python\">import pydicom\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n# 读取DICOM文件\r\nds = pydicom.dcmread('/path/to/dicom/file.dcm')\r\n# 显示图像\r\nimage = ds.pixel_array\r\nplt.imshow(image, cmap='gray')\r\nplt.axis('off')\r\nplt.show()</code></pre>"
        }
      ],
      "link": "posts/dicom-image.html",
      "metaText": "2025-11-18 | 分类：计算成像 | 标签：DICOM,图像处理"
    },
    {
      "id": "11393",
      "slug": "importance-sampling",
      "title": "重要性采样与Off-Policy强化学习",
      "createdAt": "2025-11-13",
      "day": "13",
      "month": "Nov",
      "categories": [
        "数学研究",
        "人工智能"
      ],
      "tags": [
        "数学推导",
        "强化学习",
        "蒙特卡洛"
      ],
      "summary": [
        {
          "type": "h2",
          "html": "什么是重要性采样？"
        },
        {
          "type": "p",
          "html": "<strong>重要性采样（Importance Sampling, IS）</strong>\r\n                                是一种经典的<strong>蒙特卡洛方法</strong>，主要用于在无法直接从目标分布采样，或者直接采样效率低下的情况下，<strong>估计</strong>某个函数在目标分布下的<strong>期望值</strong>。"
        },
        {
          "type": "p",
          "html": "它的核心思想非常直观：当我们想计算函数$f(x)$在目标分布$p(x)$下的期望$E_{x\\sim\r\n                                p(x)}[f(x)]$时，如果直接从$p(x)$采样很困难（例如$p(x)$形式复杂），或者$f(x)$的高值区域在$p(x)$中出现的概率极低（即「稀有事件」），我们可以转而从另一个更容易采样、或更能「聚焦」于重要区域的<strong>辅助分布</strong>$q(x)$中抽取样本。"
        },
        {
          "type": "p",
          "html": "为了弥补从$q(x)$而非$p(x)$采样所带来的偏差，我们需要对每个样本进行「加权修正」。这个权重被称为<strong>重要性权重（Importance\r\n                                    Weight）</strong>:\r\n                                $$\r\n                                w(x) = \\frac{p(x)}{q(x)} \\tag{1}\r\n                                $$\r\n                                它反映了：<strong>在原分布$p(x)$下这个样本「应该有多重要」，与在$q(x)$下它的「被采到的概率」之间的比例关系。</strong>"
        }
      ],
      "link": "posts/importance-sampling.html",
      "metaText": "2025-11-13 | 分类：数学研究,人工智能 | 标签：数学推导,强化学习,蒙特卡洛"
    },
    {
      "id": "11391",
      "slug": "variable-tau",
      "title": "为什么轨迹$\\tau$是一个随机变量？",
      "createdAt": "2025-11-12",
      "day": "12",
      "month": "Nov",
      "categories": [
        "数学研究",
        "人工智能"
      ],
      "tags": [
        "数学推导",
        "强化学习"
      ],
      "summary": [
        {
          "type": "p",
          "html": "我们在上一篇文章<a\r\n                                href=\"policy-gradient.html\">策略梯度</a>中提到，轨迹$\\tau$表示Agent在环境中经历的一系列状态、动作和奖励的序列，它是一个随机变量：\r\n                            $$\\tau = \\{s_0,a_0,r_0,s_1,a_1,r_1,\\cdots,s_T\\} \\tag 1$$"
        },
        {
          "type": "h2",
          "html": "什么是随机变量？"
        },
        {
          "type": "p",
          "html": "一个随机变量就是："
        },
        {
          "type": "blockquote",
          "html": "<blockquote><p>它的取值不是固定的，而是由某个随机过程决定的。</p></blockquote>"
        },
        {
          "type": "p",
          "html": "例如："
        },
        {
          "type": "ul",
          "html": "<ul><li><strong>抛硬币</strong>：正面朝上是1，反面朝上是0，那么这个随机变量的取值就是0或1，具体取哪个值取决于抛硬币的结果。</li>\r\n                                <li><strong>掷骰子</strong>：骰子的点数是1到6中的一个整数，那么这个随机变量的取值就是1、2、3、4、5或6，具体取哪个值取决于掷骰子的结果。</li>\r\n                                <li><strong>抽奖</strong>：中奖金额是一个随机变量，可能是0元、10元、100元等，具体取哪个值取决于抽奖的结果。</li></ul>"
        },
        {
          "type": "p",
          "html": "这些都是随机变量，因为它们的取值依赖于概率分布，而不是确定性的规则。"
        }
      ],
      "link": "posts/variable-tau.html",
      "metaText": "2025-11-12 | 分类：数学研究,人工智能 | 标签：数学推导,强化学习"
    },
    {
      "id": "11392",
      "slug": "policy-gradient",
      "title": "策略梯度",
      "createdAt": "2025-11-11",
      "day": "11",
      "month": "Nov",
      "categories": [
        "人工智能",
        "数学研究"
      ],
      "tags": [
        "数学推导",
        "强化学习"
      ],
      "summary": [
        {
          "type": "p",
          "html": "基于策略的强化学习算法的核心本质是在一个不确定的环境中，学习出一种行为方式（策略），使得Agent按照这种行为方式和环境交互的时候可以得到环境给予的最大回报。"
        },
        {
          "type": "h2",
          "html": "策略到底是个啥？"
        },
        {
          "type": "p",
          "html": "策略就是Agent的行为规律，当Agent的处在一个确定的状态$s$的时候，需要决定执行什么动作$a$，选择的依据就是策略。"
        },
        {
          "type": "p",
          "html": "最一般的情况，Agent不一定每次都要做出同样的动作，因为有时候探索是必要的。形式上，策略是从状态空间到动作概率分布的映射：\r\n                                $$\\pi(a|s) = P(A_t=a|S_t=s) \\tag 1$$\r\n                                上面的公式表示，在状态$s$下，Agent选择动作$a$的概率是多少。"
        },
        {
          "type": "p",
          "html": "在理论上，如果你知道："
        },
        {
          "type": "ul",
          "html": "<ul><li>环境的全部状态转移概率 $P(s'|s,a)$；</li>\r\n                                <li>即时奖励函数 $r(s,a)$；</li>\r\n                                <li>折扣因子 $\\gamma$；</li></ul>"
        }
      ],
      "link": "posts/policy-gradient.html",
      "metaText": "2025-11-11 | 分类：人工智能,数学研究 | 标签：数学推导,强化学习"
    },
    {
      "id": "11389",
      "slug": "verl-code-preview",
      "title": "VERL代码走读",
      "createdAt": "2025-11-10",
      "day": "10",
      "month": "Nov",
      "categories": [
        "工程实践",
        "人工智能"
      ],
      "tags": [
        "VERL",
        "动手实践"
      ],
      "summary": [
        {
          "type": "p",
          "html": "VERL代码走读"
        }
      ],
      "link": "posts/verl-code-preview.html",
      "metaText": "2025-11-10 | 分类：工程实践,人工智能 | 标签：VERL,动手实践"
    },
    {
      "id": "11388",
      "slug": "ct-recon-basic",
      "title": "CT重建基础原理",
      "createdAt": "2025-11-07",
      "day": "7",
      "month": "Nov",
      "categories": [
        "计算成像"
      ],
      "tags": [
        "技术分享"
      ],
      "summary": [
        {
          "type": "p",
          "html": "这是我们在医院通常可以看到的一个拍摄CT的机器的图片。"
        },
        {
          "type": "figure",
          "html": "<figure><img src=\"../assets/11388/ct-device.png\" alt=\"CT设备\">\r\n                            <figcaption>CT设备</figcaption></figure>"
        },
        {
          "type": "p",
          "html": "CT设备得到的图片跟我们平时体检时拍摄的X光片（DR）不太一样，X光片是二维的投影图像，而CT图像是三维的体积数据，可以通过对二维投影图像进行重建得到。CT可以实现高分辨率的，横断面的图像采集，能够清晰地显示人体内部的结构信息，因此在医学影像中有着广泛的应用。"
        }
      ],
      "link": "posts/ct-recon-basic.html",
      "metaText": "2025-11-07 | 分类：计算成像 | 标签：技术分享"
    },
    {
      "id": "11386",
      "slug": "sft-finetune-qwen2_5vl-7b",
      "title": "使用SFT微调Qwen2.5-VL-7B模型",
      "createdAt": "2025-11-07",
      "day": "7",
      "month": "Nov",
      "categories": [
        "人工智能",
        "工程实践"
      ],
      "tags": [
        "模型微调"
      ],
      "summary": [
        {
          "type": "p",
          "html": "使用SFT微调Qwen2.5-VL-7B模型"
        }
      ],
      "link": "posts/sft-finetune-qwen2_5vl-7b.html",
      "metaText": "2025-11-07 | 分类：人工智能,工程实践 | 标签：模型微调"
    }
  ]
}
